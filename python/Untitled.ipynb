{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Fruits (1).ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1_SiyyiMwPHzOj32rGLfCkx6F3hWyv-xo\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(color_codes=True)\n",
    "# %matplotlib inline\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import io\n",
    "df2 = pd.read_csv(io.BytesIO(uploaded['fruits.csv']),delim_whitespace=True)\n",
    "\n",
    "df2.head(n=8)\n",
    "\n",
    "print(df2['fruit_name'].unique())\n",
    "\n",
    "import seaborn as sns\n",
    "sns.countplot(df2['fruit_name'],label=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df2[feature_names]\n",
    "y = df2['fruit_label']\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap('gnuplot')\n",
    "\n",
    "scatter = pd.plotting.scatter_matrix(X, c = y, marker = 'o', s=40, hist_kwds={'bins':15}, figsize=(9,9), cmap = cmap)\n",
    "plt.suptitle('Scatter-matrix for each input variable')\n",
    "plt.savefig('fruits_scatter_matrix')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf2.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as mpatches\n",
    "import sklearn\n",
    "X = df2[['mass', 'width', 'height', 'color_score']]\n",
    "y = df2['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "def plot_fruit_knn(X, y, n_neighbors, weights):\n",
    "    X_mat = X[['height', 'width']].as_matrix()\n",
    "    y_mat = y.as_matrix()\n",
    "\n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF','#AFAFAF'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#00FF00', '#0000FF','#AFAFAF'])\n",
    "\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X_mat, y_mat)\n",
    "\n",
    "    # Plot the decision boundary by assigning a color in the color map\n",
    "    # to each mesh point.\n",
    "    \n",
    "    mesh_step_size = .01  # step size in the mesh\n",
    "    plot_symbol_size = 50\n",
    "    \n",
    "    x_min, x_max = X_mat[:, 0].min() - 1, X_mat[:, 0].max() + 1\n",
    "    y_min, y_max = X_mat[:, 1].min() - 1, X_mat[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size),\n",
    "                         np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot training points\n",
    "    plt.scatter(X_mat[:, 0], X_mat[:, 1], s=plot_symbol_size, c=y, cmap=cmap_bold, edgecolor = 'black')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "    patch0 = mpatches.Patch(color='#FF0000', label='apple')\n",
    "    patch1 = mpatches.Patch(color='#00FF00', label='mandarin')\n",
    "    patch2 = mpatches.Patch(color='#0000FF', label='orange')\n",
    "    patch3 = mpatches.Patch(color='#AFAFAF', label='lemon')\n",
    "    plt.legend(handles=[patch0, patch1, patch2, patch3])\n",
    "\n",
    "        \n",
    "    plt.xlabel('height (cm)')\n",
    "    plt.ylabel('width (cm)')\n",
    "    plt.title(\"4-Class classification (k = %i, weights = '%s')\"\n",
    "#               % (n_neighbors, weights))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_fruit_knn(X_train, y_train, 5, 'uniform')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
